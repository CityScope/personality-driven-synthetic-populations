"""
stochastics.py

This script compares demographic distributions between synthetic populations
generated by different language models (LLaMA, Dolphin, Mistral, Qwen) and
real-world Cambridge data.

This section specifically computes and visualizes population pyramids, showing
how the synthetic age/gender structure compares to the actual Cambridge population.

Author: José Miguel Nicolás García
"""
import json
import matplotlib.pyplot as plt
import numpy as np
from collections import Counter, defaultdict
import matplotlib.pyplot as plt

# Define file paths for synthetic datasets
model_files = {
    "LLaMA": "profiles_cambridge-llama3.1_8b.json",
    "Dolphin": "profiles_cambridge-dolphin-llama3_8b.json",
    "Mistral": "profiles_cambridge-mistral_7b.json",
    "Qwen": "profiles_cambridge-qwen3_8b.json"
}

# Assign color per model for consistent visualizations
model_colors = {
    "LLaMA": "#4E79A7",   # blue
    "Dolphin": "#59A14F",   # green
    "Mistral":  "#F28E2B",   # orange
    "Qwen": "#E15759"       # red
}



# Matplotlib font size settings for better readability in PDF output
plt.rcParams.update({
    'font.size': 14,
    'axes.titlesize': 16,
    'axes.labelsize': 16,
    'xtick.labelsize': 14,
    'ytick.labelsize': 13,
    'legend.fontsize': 13,
    'figure.titlesize': 18
})


output_path = "./population_pyramids_comparison.png"


# === Section: Population Pyramid ===


# Load the original Cambridge population data
age_brackets = [(0, 4), (5, 9), (10, 14), (15, 19), (20, 24), (25, 29), (30, 34), (35, 39),
                (40, 44), (45, 49), (50, 54), (55, 59), (60, 64), (65, 69), (70, 74), (75, 79), 
                (80, 84), (85, 100)]  
male_population_raw = [2941, 2053, 1765, 4131, 8351, 9733, 7203, 4754, 3187, 2637, 2164, 2126, 2140, 1989, 1773, 968, 627, 591]
female_population_raw = [2001, 1720, 1598, 4690, 8715, 9031, 6091, 4808, 2864, 2619, 2383, 2109, 2128, 2596, 2169, 1448, 843, 1016]

# Convert reference population to percentage of total population
total_population_ref = sum(male_population_raw) + sum(female_population_raw)
male_population = [v / total_population_ref * 100 for v in male_population_raw]
female_population = [v / total_population_ref * 100 for v in female_population_raw]

# Prepare age labels
age_bins = [f"{a[0]}-{a[1]}" for a in age_brackets]
n_bins = len(age_brackets)

# Initialize synthetic population storage
synthetic_data = {model: {'Male': [0]*n_bins, 'Female': [0]*n_bins} for model in model_files}

# Function to get age bin index
def get_bin_index(age):
    for i, (low, high) in enumerate(age_brackets):
        if low <= age <= high:
            return i
    return None

# Parse and bin each profile
for model, filename in model_files.items():
    with open(f"./{filename}") as f:
        data = json.load(f)
        for person in data:
            try:
                age = int(person["General"]["Age"])
                gender = person["Identity"]["Gender"]
                idx = get_bin_index(age)
                if idx is not None and gender in ["Male", "Female"]:
                    synthetic_data[model][gender][idx] += 1
            except Exception:
                continue

# Convert synthetic counts to percentages of total synthetic population
for model in model_files:
    total_population = sum(synthetic_data[model]["Male"]) + sum(synthetic_data[model]["Female"])
    if total_population > 0:
        synthetic_data[model]["Male"] = [v / total_population * 100 for v in synthetic_data[model]["Male"]]
        synthetic_data[model]["Female"] = [v / total_population * 100 for v in synthetic_data[model]["Female"]]

# Compute MAE per model
model_scores = {}
for model in model_files:
    mae = 0
    for real_m, real_f, pred_m, pred_f in zip(
        male_population, female_population,
        synthetic_data[model]["Male"], synthetic_data[model]["Female"]
    ):
        error_m = abs(real_m - pred_m)
        error_f = abs(real_f - pred_f)
        mae += error_m + error_f
    mae /= (2 * n_bins)
    model_scores[model] = round(mae, 3)

# Plotting
x = np.arange(n_bins)
bar_width = 0.35

fig, axs = plt.subplots(2, 2, figsize=(14, 10))
for i, model in enumerate(model_files.keys()):
    ax = axs.flat[i]
    color = model_colors[model]

    # Reference data
    male_ref = [-v for v in male_population]
    female_ref = female_population

    # Synthetic data
    male_syn = [-v for v in synthetic_data[model]["Male"]]
    female_syn = synthetic_data[model]["Female"]

    # Plot reference
    ax.barh(x - bar_width/2, male_ref, height=bar_width, label='Cambridge Male', color='black', alpha=0.6)
    ax.barh(x - bar_width/2, female_ref, height=bar_width, label='Cambridge Female', color='#444444', alpha=0.6)

    # Plot synthetic
    ax.barh(x + bar_width/2, male_syn, height=bar_width, label=f'{model} Male', color=color, alpha=0.7)
    ax.barh(x + bar_width/2, female_syn, height=bar_width, label=f'{model} Female', color=color, alpha=0.3)

    # Styling
    ax.set_yticks(x)
    ax.set_yticklabels(age_bins)
    ax.axvline(0, color='black', linewidth=0.8)
    ax.set_xlabel('Male      Percentage of Total Population (%)      Female')
    ax.set_xlim(-10, 10)
    ax.set_title(f'{model}\nMAE: {model_scores[model]}%')

# Set shared labels (left = Male, right = Female)



# Global layout
fig.suptitle('Population Pyramid Comparison: Synthetic Models vs. Cambridge', fontsize=16)
plt.tight_layout()
plt.subplots_adjust(top=0.90)

# Save figure
fig.savefig(output_path, dpi=300)




# === Section: Country of Origin ===




country_mapping = {
    "American": "United States",
    "United States citizen": "United States",
    "Brazilian-American": "Brazil",
    "Brazilian": "Brazil",
    "Indian-American": "India",
    "Indian": "India",
    "Chinese-American": "China",
    "Chinese": "China",
    "Vietnamese-American": "Vietnam",
    "Vietnamese": "Vietnam",
    "Puerto Rican": "Puerto Rico",
    "Dominican-American": "Dominican Republic",
    "Dominican Republic": "Dominican Republic",
    "Korean-American": "South Korea",
    "Colombian-American": "Colombia",
    "Colombian": "Colombia",
    "Jamaican-American": "Jamaica",
    "Jamaican": "Jamaica",
    "Guatemalan-American": "Guatemala",
    "Guatemalan": "Guatemala",
    "Guatemala": "Guatemala",
    "Filipino-American": "Philippines",
    "Filipino": "Philippines",
    "Mexican-American": "Mexico",
    "Mexican": "Mexico",
    "Cabo Verdean-American": "Cabo Verde",
    "Cabo Verdean": "Cabo Verde",
    "Cabo Verde": "Cabo Verde",
    "Haitian-American": "Haiti",
    "Haitian": "Haiti",
    "Haiti": "Haiti",
    "German-American": "Germany",
    "German": "Germany",
    "Italian-American": "Italy",
    "Italian": "Italy",
    "Russian-American": "Russia",
    "Russian": "Russia",
    "El Salvadoran-American": "El Salvador",
    "El Salvadorian-American": "El Salvador",
    "El Salvadoran": "El Salvador",
    "El Salvadorian": "El Salvador",
    "El Salvador": "El Salvador",
    "Canadian": "Canada",
    "Hong Kong Chinese": "Hong Kong",
    "Hong Kong-born": "Hong Kong",
    "Chinese American": "China",
    "Vietnamese American": "Vietnam",
    "Nepali-American": "Nepal",
    "Nepalese-American": "Nepal",
    "Nepalese": "Nepal",
    "Nepal": "Nepal",
    "Polish-American": "Poland",
    "Polish": "Poland",
    "Greek-American": "Greece",
    "Greek": "Greece",
    "Cuban-American": "Cuba",
    "Cuban": "Cuba",
    "French-American": "France",
    "French": "France",
    "British-American": "United Kingdom",
    "British": "United Kingdom",
    "United Kingdom (born), American (resident)": "United Kingdom",
    "United Kingdom, not specified": "United Kingdom",
    "Irish-American": "Ireland",
    "Irish": "Ireland",
    "Portuguese-American": "Portugal",
    "Portuguese": "Portugal",
    "Spanish-American": "Spain",
    "Spanish": "Spain",
    "Israeli-American": "Israel",
    "Israeli": "Israel",
    "Albanian-American": "Albania",
    "Albanian": "Albania",
    "Armenian-American": "Armenia",
    "Armenian": "Armenia",
    "Belarusian-American": "Belarus",
    "Belarusian": "Belarus",
    "Egyptian-American": "Egypt",
    "Egyptian": "Egypt",
    "Iranian-American": "Iran",
    "Iranian": "Iran",
    "Iraqi-American": "Iraq",
    "Iraqi": "Iraq",
    "Japanese-American": "Japan",
    "Japanese": "Japan",
    "Kenyan-American": "Kenya",
    "Kenyan": "Kenya",
    "Nigerian-American": "Nigeria",
    "Nigerian": "Nigeria",
    "Peruvian-American": "Peru",
    "Peruvian": "Peru",
    "Ecuadorian-American": "Ecuador",
    "Ecuadorian": "Ecuador",
    "Bangladeshi-American": "Bangladesh",
    "Bangladeshi": "Bangladesh",
    "Moroccan-American": "Morocco",
    "Moroccan": "Morocco",
    "Lebanese-American": "Lebanon",
    "Lebanese": "Lebanon",
    "Sri Lankan-American": "Sri Lanka",
    "Sri Lankan": "Sri Lanka",
    "Taiwanese-American": "Taiwan",
    "Taiwanese": "Taiwan",
    "Israeli": "Israel",
    "Guyanese-American": "Guyana",
    "Guyanese": "Guyana",
    "Kuwaiti-American": "Kuwait",
    "Jordanian": "Jordan",
    "Pakistani-American": "Pakistan",
    "Pakistani": "Pakistan",
    "Born in Pakistan and moved to the United States at age 7": "Pakistan",
    "Sudan": "Sudan",
    "Thai-American": "Thailand",
    "Thai": "Thailand",
    "Indonesian-American": "Indonesia",
    "Indonesian": "Indonesia",
    "Myanmar": "Myanmar",
    "Ukrainian-American": "Ukraine",
    "Ukrainian": "Ukraine",
    "Ugandan-American": "Uganda",
    "Ugandan": "Uganda",
    "Cameroonian-American": "Cameroon",
    "Cameroonian": "Cameroon",
    "Ethiopian-American": "Ethiopia",
    "Ethiopian": "Ethiopia",
    "Liberian-American": "Liberia",
    "Liberian": "Liberia",
    "Trinidad & Tobago": "Trinidad and Tobago",
    "Barbadian": "Barbados",
    "Barbados": "Barbados",
    "South African": "South Africa",
    "South Africa": "South Africa",
    "Zimbabwean": "Zimbabwe",
    "St Lucia": "Saint Lucia",
    "Hungary": "Hungary",
    "Syrian": "Syria",
    "Laos": "Laos",
    "Moldovan-American": "Moldova",
    "Moldovan": "Moldova",
    "Uzbekistan": "Uzbekistan",
    "Kazakhstan": "Kazakhstan",
    "Ivory Coast": "Côte d'Ivoire",
    "Democratic Republic of the Congo": "DR Congo",
    "Netherlands": "Netherlands",
    "Switzerland": "Switzerland",
    "Belgium": "Belgium",
    "Lithuania": "Lithuania",
    "Bosnia and Herzegovina": "Bosnia and Herzegovina",
    "Paraguay": "Paraguay",
    "Romanian-American": "Romania",
    "Romanian": "Romania",
    "Spain": "Spain",
    "Italy": "Italy",
    "Germany": "Germany",
    "Russia": "Russia",
    "Ukraine": "Ukraine",
    "Philippines": "Philippines",
    "Philippine": "Philippines",
    "Israel": "Israel",
    "France": "France",
    "Turkey": "Turkey",
    "Turkish-American": "Turkey",
    "Australia": "Australia",
    "New Zealand": "New Zealand",
    "Canada": "Canada",
    "Argentina": "Argentina",
    "Chile": "Chile",
    "Cuba": "Cuba",
    "Greece": "Greece",
    "Kenya": "Kenya",
    "Ghana": "Ghana",
    "Ghanaian-American": "Ghana",
    "Ghanaian": "Ghana",
    "Iraq": "Iraq",
    "Iran": "Iran",
    "Lebanon": "Lebanon"
}




def normalize_country(name):
    return country_mapping.get(name, name)



with open("cambridge_countries.json") as f:
    full_data = json.load(f)

# --- 1. Load and processing baseline (Cambridge) ---
with open("cambridge_countries.json") as f:
    full_data = json.load(f)

def normalize_country(name):
    return country_mapping.get(name, name)

baseline_counter = Counter()
valid_data = [
    entry for entry in full_data["data"]
    if "Birthplace" in entry and "Total Population" in entry
]

for entry in valid_data:
    raw_country = entry["Birthplace"]
    normalized = normalize_country(raw_country)
    baseline_counter[normalized] += entry["Total Population"]

# Proportion of foreign-born (based on demographic data)
foreign_percentage = 61.5
us_percentage = 100 - foreign_percentage

# Add only foreign-born
total_foreign_population = sum(baseline_counter.values())

#We normalize to represent 61.5 % of the total
groundtruth_distribution = {
    "United States": us_percentage,
}
for country, count in baseline_counter.items():
    adjusted = (count / total_foreign_population) * foreign_percentage
    groundtruth_distribution[country] = adjusted


# ---2.Load synthetic models --- 
def load_model_distribution(filepath, top_n=20):
    with open(filepath) as f:
        data = json.load(f)
    counter = Counter()
    for person in data:
        try:
            nationality = normalize_country(person["Identity"]["Nationality"])
            counter[nationality] += 1
        except KeyError:
            continue
    total = sum(counter.values())
    most_common = counter.most_common(top_n)
    result = {k: v / total * 100 for k, v in most_common}
    other_count = 100 - sum(result.values())
    if other_count > 0:
        result["Other"] = other_count
    return result

synthetic_distributions = {
    model: load_model_distribution(path)
    for model, path in model_files.items()
}

# --- 3. Trim real (top-N + Sonstiges) ---
top_n = 20
sorted_real = sorted(groundtruth_distribution.items(), key=lambda x: x[1], reverse=True)
top_real = dict(sorted_real[:top_n])
top_real["Other"] = 100 - sum(top_real.values())
reference_distribution_processed = top_real

# --- 4. Country List---
all_countries = set(reference_distribution_processed.keys())
for dist in synthetic_distributions.values():
    all_countries.update(dist.keys())
all_countries = sorted(all_countries)

# --- 5.  MAE ---
model_mae = {}
for model, dist in synthetic_distributions.items():
    mae = 0
    for country in all_countries:
        real = reference_distribution_processed.get(country, 0)
        pred = dist.get(country, 0)
        mae += abs(real - pred)
    mae /= len(all_countries)
    model_mae[model] = round(mae, 3)

# --- 6. Plotting ---
x = np.arange(len(reference_distribution_processed))
bar_width = 0.35
fig, axs = plt.subplots(2, 2, figsize=(14, 10))

top_countries = list(reference_distribution_processed.keys())

for ax, (model, color) in zip(axs.flat, model_colors.items()):
    real_vals = [reference_distribution_processed.get(c, 0) for c in top_countries]
    model_vals = [synthetic_distributions[model].get(c, 0) for c in top_countries]

    ax.bar(x - bar_width/3, real_vals, width=bar_width * 0.6, label="Cambridge", color='#444444', alpha=0.8)
    ax.bar(x + bar_width/3, model_vals, width=bar_width, label=model, color=model_colors[model], alpha=0.85)


    ax.set_xticks(x)
    ax.set_xticklabels(top_countries, rotation=45, ha='right')
    ax.set_ylim(0, max(real_vals + model_vals) + 5)
    ax.set_ylabel("Percentage of Population")
    ax.set_title(f"{model} (MAE: {model_mae[model]}%)")

fig.suptitle("Country of Origin: Synthetic Models vs. Cambridge", fontsize=16, y=0.94)
plt.tight_layout(rect=[0, 0.02, 1, 0.95])
plt.savefig("country_distribution_comparison.png", dpi=300)

# --- 8. Top 20 most common words by model ---
model_top_countries = {"Cambridge": baseline_counter.most_common(20)}

for model, path in model_files.items():
    with open(path) as f:
        data = json.load(f)
    counter = Counter()
    for person in data:
        try:
            nationality = normalize_country(person["Identity"]["Nationality"])
            counter[nationality] += 1
        except KeyError:
            continue
    model_top_countries[model] = counter.most_common(20)

# Print results
# for model in model_top_countries:
#     print(f"\nTop 20 countries for {model}")
#     print("-" * 35)
#     for country, count in model_top_countries[model]:
#         print(f"{country:<25} {count}")







# === Section: Income distribution===

# --- Cambridge Real Data ---
industries = [
    "Agriculture, Forestry", "Mining, Quarrying, & Oil", "Construction", "Manufacturing",
    "Wholesale Trade", "Retail Trade", "Transportation", "Utilities", "Information",
    "Finance & Insurance", "Real Estate & Rental", "Professional, Scientific, & Technical Services",
    "Management", "Administrative Services", "Educational Services", "Health Care & Social Assistance",
    "Arts, Entertainment, & Recreation", "Accommodation & Food Services", "Others: (Extrange industry)"
]

workers = [161, 5, 932, 4840, 474, 3690, 127000, 321, 2380, 3070, 929, 16700, 57, 111, 195000, 8220, 133000, 1920, 2200]
salaries = [232000, 29000, 142000, 212000, 156000, 74700, 86600, 204000, 223000, 216000, 159000, 212000, 209000, 95900,
            100000, 129000, 56000, 38300, 66000]



baseline_avg_salary = dict(zip(industries, salaries))
baseline_worker_counts = dict(zip(industries, workers))
total_baseline_workers = sum(workers)
baseline_worker_percentages = {
    ind: count / total_baseline_workers * 100 for ind, count in baseline_worker_counts.items()
}

# Industry name normalization
industry_mapping = {
    "Higher Education": "Educational Services", "Education": "Educational Services",
    "K-12 Education": "Educational Services", "K-12 Public Education": "Educational Services",
    "Public Education": "Educational Services", "Arts and Entertainment": "Arts, Entertainment, & Recreation",
    "Arts, Entertainment & Recreation": "Arts, Entertainment, & Recreation",
    "Arts, Entertainment, and Recreation": "Arts, Entertainment, & Recreation",
    "Arts, Entertainment, &amp; Recreation": "Arts, Entertainment, & Recreation",
    "Visual Arts": "Arts, Entertainment, & Recreation",
    "Visual Arts: Painting and Sculpture": "Arts, Entertainment, & Recreation",
    "Film Production": "Arts, Entertainment, & Recreation",
    "Graphic Design and Illustration": "Arts, Entertainment, & Recreation",
    "Creative Services": "Arts, Entertainment, & Recreation", "Arts": "Arts, Entertainment, & Recreation",
    "Transportation and Infrastructure": "Transportation", "Transportation Infrastructure": "Transportation",
    "Transportation Logistics": "Transportation", "Transportation and Logistics": "Transportation",
    "Transportation Engineering": "Transportation", "Transportation Management": "Transportation",
    "Transportation Industry": "Transportation", "Information Technology": "Information", "Technology": "Information",
    "Software Development": "Information", "Technology Consulting": "Information",
    "Healthcare/Veterinary Medicine": "Health Care & Social Assistance",
    "Healthcare/Veterinary Services": "Health Care & Social Assistance",
    "Nonprofit Sector": "Health Care & Social Assistance", "Finance  & Insurance": "Finance & Insurance",
    "Automotive Manufacturing": "Manufacturing", "Student": "Others: (Extrange industry)"
}

def normalize_industry(name):
    return industry_mapping.get(name, name)



# Initialize result holders
model_avg_salary = {}
model_worker_percentages = {}
model_worker_counts = {}
mae_salary = {}
mae_salary_pct = {}
mae_worker = {}

# Parse data
for model, path in model_files.items():
    with open(path) as f:
        data = json.load(f)

    salary_dict = defaultdict(list)
    for person in data:
        try:
            raw_industry = person["Profession"]["Industry"]
            industry = normalize_industry(raw_industry)
            salary = person["Profession"]["Personal Salary"]
            if isinstance(salary, str) or salary == "Unemployed":
                continue
            salary_dict[industry].append(int(salary))
        except:
            continue

    counts = {ind: len(vals) for ind, vals in salary_dict.items()}
    total = sum(counts.values())
    model_worker_counts[model] = counts
    model_worker_percentages[model] = {ind: c / total * 100 for ind, c in counts.items()}
    model_avg_salary[model] = {ind: np.mean(vals) if vals else None for ind, vals in salary_dict.items()}

    # MAE calculations
    mae_s_abs = 0
    mae_s_pct = 0
    valid_salary_count = 0
    mae_w = 0

    for ind in industries:
        real_s = baseline_avg_salary.get(ind, 0)
        pred_s = model_avg_salary[model].get(ind)
        if real_s > 0 and pred_s is not None:
            mae_s_abs += abs(real_s - pred_s)
            mae_s_pct += abs(real_s - pred_s) / real_s * 100
            valid_salary_count += 1

        real_w = baseline_worker_percentages.get(ind, 0)
        pred_w = model_worker_percentages[model].get(ind, 0)
        mae_w += abs(real_w - pred_w)

    mae_salary[model] = round(mae_s_abs / valid_salary_count, 2)
    mae_salary_pct[model] = round(mae_s_pct / valid_salary_count, 2)
    mae_worker[model] = round(mae_w / len(industries), 2)

# Plot
x = np.arange(len(industries))
bar_width = 0.15
fig, axs = plt.subplots(2, 1, figsize=(16, 10), sharex=True)

# Salary plot
axs[0].bar(x - bar_width*2, [baseline_avg_salary.get(ind, 0) for ind in industries],
           width=bar_width, label="Cambridge", color="#444444")
for i, (model, color) in enumerate(model_colors.items()):
    offset = (i + 1 - 2) * bar_width
    vals = [model_avg_salary[model].get(ind, 0) or 0 for ind in industries]
    axs[0].bar(x + offset, vals, width=bar_width,
               label=f"{model} (MAE: {mae_salary[model]}$ / {mae_salary_pct[model]}%)", color=color)
axs[0].set_ylabel("Average Salary (USD)")
axs[0].set_title("Average Salary by Industry")
axs[0].tick_params(labelbottom=False)
axs[0].legend()

# Worker plot
axs[1].bar(x - bar_width*2, [baseline_worker_percentages.get(ind, 0) for ind in industries],
           width=bar_width, label="Cambridge", color="#444444")
for i, (model, color) in enumerate(model_colors.items()):
    offset = (i + 1 - 2) * bar_width
    vals = [model_worker_percentages[model].get(ind, 0) for ind in industries]
    axs[1].bar(x + offset, vals, width=bar_width,
               label=f"{model} (MAE: {mae_worker[model]}%)", color=color)
axs[1].set_ylabel("Workers (% of total)")
axs[1].set_title("Worker Share by Industry")
axs[1].set_xticks(x)
axs[1].set_xticklabels(industries, rotation=45, ha="right")
axs[1].legend()

fig.suptitle("Salary and Workforce Distribution by Industry", fontsize=16, y=0.99)
plt.tight_layout(rect=[0, 0.03, 1, 0.96])
plt.savefig("industry_salary_worker_comparison.png", dpi=300)


top_n = 20

# def print_top_industries(model, worker_counts, avg_salary):
#     print(f"\n{model}")
#     print("-" * 50)
#     sorted_inds = sorted(worker_counts.items(), key=lambda x: x[1], reverse=True)[:top_n]
#     for industry, count in sorted_inds:
#         salary = avg_salary.get(industry, None)
#         if salary is None:
#             print(f"{industry:<40} Num: {count} Salary avg: N/A")
#         else:
#             print(f"{industry:<40} Num: {count} Salary avg: ${salary:,.0f}")


# print_top_industries("Baseline (Cambridge)", baseline_worker_counts, baseline_avg_salary)


# for model in model_files.keys():
#     print_top_industries(model, model_worker_counts[model], model_avg_salary[model])


# === Section: Education===


education_normalization = {
    "nursery": "Nursery school, preschool",
    "preschool": "Nursery school, preschool",
    "kindergarten": "Kindergarten",
    "college": "Attending College, Undergraduate",
    "undergraduate": "Attending College, Undergraduate",
    "high school": "High school or equivalent degree",
    "highschool": "High school or equivalent degree",
    "some college": "Some college, no degree",
    "associate": "Associate's degree",
    "bachelor": "Bachelor's degree",
    "ba": "Bachelor's degree",
    "master": "Graduate or professional degree",
    "m.": "Graduate or professional degree",
    "mba": "Graduate or professional degree",
    "mfa": "Graduate or professional degree",
    "graduate": "Graduate or professional degree",
    "phd": "Graduate or professional degree",
    "ph.d.": "Graduate or professional degree",
    "doctor": "Graduate or professional degree",
    "doctorate": "Graduate or professional degree",
}

def normalize_education(text):
    if not isinstance(text, str):
        return None
    text_l = text.lower()
    for key, category in education_normalization.items():
        if key in text_l:
            return category
    return text.strip()  # ←  returns the original if it cannot be mapped

# Merge categories: College
def fuse_college_categories(counter):
    fused = Counter()
    for k, v in counter.items():
        if k in ["Attending College, Undergraduate", "Some college, no degree"]:
            fused["Some College or Attending"] += v
        else:
            fused[k] += v
    return fused


# Calculate baseline distribution (approximated from generator logic)
baseline_dist = defaultdict(float)

# Enrollment group (ages 3–22)
enrollment_data = [
    {"age_range": (3, 4), "enrollment_rate": 74.8, "level": "Nursery school, preschool"},
    {"age_range": (5, 9), "enrollment_rate": 96.6, "level": "Kindergarten"},
    {"age_range": (10, 17), "enrollment_rate": 100.0, "level": "Kindergarten"},
    {"age_range": (18, 19), "enrollment_rate": 99.0, "level": "Attending College, Undergraduate"},
    {"age_range": (20, 22), "enrollment_rate": 69.7, "level": "Attending College, Undergraduate"}
]

# Assume uniform population across ages
total_population = 0
for entry in enrollment_data:
    years = entry["age_range"][1] - entry["age_range"][0] + 1
    weight = years
    total_population += weight
    baseline_dist[entry["level"]] += entry["enrollment_rate"] / 100 * weight

# Adult education group (age >= 22)
adult_edu_levels = [
    'High school or equivalent degree',
    'Some college, no degree',
    'Associate\'s degree',
    'Bachelor\'s degree',
    'Graduate or professional degree'
]
adult_probs = [6.0, 5.3, 3.0, 27.9, 54.8]
adult_total = sum(adult_probs)
adult_probs = [p / adult_total for p in adult_probs]

# Assume 78 units of adult population
adult_weight = 78
total_population += adult_weight
for level, p in zip(adult_edu_levels, adult_probs):
    baseline_dist[level] += p * adult_weight

# Normalize to percentage
for k in baseline_dist:
    baseline_dist[k] = baseline_dist[k] / total_population * 100

baseline_dist = fuse_college_categories(baseline_dist)

# Now process synthetic models
synthetic_dists = {}

for model, filepath in model_files.items():
    with open(filepath) as f:
        data = json.load(f)
    
    counter = Counter()
    for person in data:
        try:
            age = int(person["General"]["Age"])
            edu_raw = person["General"]["Education"]
            edu = normalize_education(edu_raw)

            if age < 3:
                continue  # Ignore too young
            elif age <= 22:
                if edu in ["Nursery school, preschool", "Kindergarten", "Attending College, Undergraduate"]:
                    counter[edu] += 1
            else:
                counter[edu] += 1
        except:
            continue

    counter = fuse_college_categories(counter)

    total = sum(counter.values())
    dist = {k: v / total * 100 for k, v in counter.items()}
    synthetic_dists[model] = dist

# Build full list of categories
all_categories = list(baseline_dist.keys())

# Compute MAE
model_mae = {}
for model, dist in synthetic_dists.items():
    mae = 0
    for cat in all_categories:
        real = baseline_dist.get(cat, 0)
        pred = dist.get(cat, 0)
        mae += abs(real - pred)
    model_mae[model] = round(mae / len(all_categories), 2)

# Plotting
x = np.arange(len(all_categories))
bar_width = 0.15

fig, ax = plt.subplots(figsize=(16, 8))

# Baseline
baseline_vals = [baseline_dist.get(cat, 0) for cat in all_categories]
ax.bar(x - 2*bar_width, baseline_vals, width=bar_width, label="Cambridge", color="#444444")

# Models
for i, (model, color) in enumerate(model_colors.items()):
    offset = (i - 1) * bar_width
    vals = [synthetic_dists[model].get(cat, 0) for cat in all_categories]
    ax.bar(x + offset, vals, width=bar_width, label=f"{model} (MAE: {model_mae[model]}%)", color=color)

# Styling
ax.set_ylabel("Percentage of Population")
ax.set_title("Education Level Distribution Comparison: Synthetic Models vs. Cambridge")
ax.set_xticks(x)
ax.set_xticklabels(all_categories, rotation=45, ha="right")
ax.legend()
plt.tight_layout()
plt.savefig("education_distribution_comparison.png", dpi=300)

# ---Print 4 categories per model ---
def print_top_categories(name, dist, top_n=20):
    print(f"\n{name}")
    print("-" * 40)

    none_pct = dist.pop("__None__", None)

    sorted_items = [
        (cat, pct) for cat, pct in dist.items()
        if cat is not None and isinstance(pct, (int, float))
    ]
    sorted_items = sorted(sorted_items, key=lambda x: x[1], reverse=True)[:top_n]

    for cat, pct in sorted_items:
        print(f"{cat:<40} {pct:.2f}%")

    if none_pct is not None:
        print(f"{'Unmapped / None':<40} {none_pct:.2f}%")  # <-- Aquí lo ves



# # Baseline
# print_top_categories("Cambridge", baseline_dist)

# # Models
# for model in model_files.keys():
#     print_top_categories(model, synthetic_dists[model])

# === Section: Sexual Orientation===
# Construir distribución baseline
age_groups = {
    "0-24": 15.5, "25-34": 10.4, "35-44": 6.0,
    "45-54": 5.7, "55-64": 5.3, "65-100": 2.7
}

lgbt_identities = ['Homosexual', 'Bisexual', 'Transgender', 'Pansexual', 'Asexual', 'Queer', 'Other LGBT+']
lgbt_probs = [33.2, 57.3, 11.8, 1.7, 1.3, 0.1, 1.1]
lgbt_probs = [p / sum(lgbt_probs) for p in lgbt_probs]

from collections import defaultdict
baseline_orientation = defaultdict(float)
total_weight = 0

for age_range, p_lgbt in age_groups.items():
    age_min, age_max = map(int, age_range.split('-'))
    span = age_max - age_min + 1
    total_weight += span

    for ident, p in zip(lgbt_identities, lgbt_probs):
        baseline_orientation[ident] += span * (p_lgbt / 100) * p
    baseline_orientation["Heterosexual, CIS"] += span * (1 - p_lgbt / 100)

for k in baseline_orientation:
    baseline_orientation[k] = baseline_orientation[k] / total_weight * 100


orientation_map = {
    "gay": "Homosexual", "lesbian": "Homosexual", "homosexual": "Homosexual",
    "bi": "Bisexual", "bisexual": "Bisexual",
    "trans": "Transgender", "transgender": "Transgender",
    "pansexual": "Pansexual", "asexual": "Asexual", "queer": "Queer", "other": "Other LGBT+",
    "heterosexual": "Heterosexual, CIS", "straight": "Heterosexual, CIS", "cis": "Heterosexual, CIS"
}

def normalize_orientation(text):
    if not isinstance(text, str):
        return None
    text_l = text.lower()
    for key, val in orientation_map.items():
        if key in text_l:
            return val
    return text.strip()


model_orientation = {}
orientation_mae = {}

for model, filepath in model_files.items():
    with open(filepath) as f:
        data = json.load(f)

    counter = Counter()
    for person in data:
        try:
            raw = person["Identity"]["Sexual Orientation"]
            norm = normalize_orientation(raw)
            counter[norm] += 1
        except:
            continue

    total = sum(counter.values())
    dist = {k: v / total * 100 for k, v in counter.items()}
    model_orientation[model] = dist

    # MAE
    mae = 0
    for cat in baseline_orientation:
        real = baseline_orientation.get(cat, 0)
        pred = dist.get(cat, 0)
        mae += abs(real - pred)
    orientation_mae[model] = round(mae / len(baseline_orientation), 2)



def print_top_orientation(name, dist, top_n=30):
    print(f"\n{name}")
    print("-" * 40)
    for cat, pct in sorted(dist.items(), key=lambda x: x[1], reverse=True)[:top_n]:
        print(f"{cat:<30} {pct:.2f}%")

print_top_orientation("Cambridge", baseline_orientation)
for model in model_files:
    print_top_orientation(model, model_orientation[model])
    print(f"MAE: {orientation_mae[model]}%")




# === Section: Religions===



religions = [
    "Evangelical Protestant", "Mainline Protestant", "Catholic", "Mormon",
    "Orthodox Christian", "Jehovah's Witness", "Other Christian",
    "Jewish", "Muslim", "Buddhist", "Hindu", "Other World Religions",
    "Other Faiths", "Atheist", "Agnostic", "Nothing in particular", "Don't know"
]

probs = [
    9, 13, 29, 1, 2, 1, 1,  # Christian
    4, 1, 1, 1, 1, 2,       # Other religions
    4, 9, 20, 1             # Unaffiliated
]

# Normalize to 100%
total = sum(probs)
baseline_religion = {rel: p / total * 100 for rel, p in zip(religions, probs)}

religion_map = {
    "evangelical": "Evangelical Protestant",
    "mainline": "Mainline Protestant",
    "protestant": "Mainline Protestant",
    "catholic": "Catholic",
    "mormon": "Mormon",
    "orthodox": "Orthodox Christian",
    "jehovah": "Jehovah's Witness",
    "christian": "Other Christian",
    "jewish": "Jewish",
    "muslim": "Muslim",
    "islam": "Muslim",
    "buddh": "Buddhist",
    "hindu": "Hindu",
    "world": "Other World Religions",
    "faith": "Other Faiths",
    "atheist": "Atheist",
    "agnostic": "Agnostic",
    "nothing": "Nothing in particular",
    "don't know": "Don't know",
    "dont know": "Don't know"
}

def normalize_religion(text):
    if not isinstance(text, str):
        return "__None__"
    text_l = text.lower()
    for key, val in religion_map.items():
        if key in text_l:
            return val
    return "__None__"  




model_religion = {}
religion_mae = {}

for model, filepath in model_files.items():
    with open(filepath) as f:
        data = json.load(f)

    counter = Counter()
    for person in data:
        try:
            raw = person["Identity"]["Religious Beliefs"]
            norm = normalize_religion(raw)
            counter[norm] += 1
        except:
            continue

    total = sum(counter.values())
    dist = {k: v / total * 100 for k, v in counter.items()}
    model_religion[model] = dist

    # MAE
    mae = 0
    for cat in baseline_religion:
        real = baseline_religion.get(cat, 0)
        pred = dist.get(cat, 0)
        mae += abs(real - pred)
    religion_mae[model] = round(mae / len(baseline_religion), 2)


def print_top_religions(name, dist, top_n=20):
    print(f"\n{name}")
    print("-" * 40)
    for cat, pct in sorted(dist.items(), key=lambda x: x[1], reverse=True)[:top_n]:
        print(f"{cat:<30} {pct:.2f}%")

print_top_religions("Cambridge", baseline_religion)
for model in model_files:
    print_top_religions(model, model_religion[model])
    print(f"MAE: {religion_mae[model]}%")


####################################################Idiology####################################################
# === Section: Idiology===

# --- Real distribution---
real_ideologies = ["Democratic", "Republican", "Libertarian", "Green", "Other"]
real_probs = [61.6, 31.9, 1.29, 0.51, 1.17]

# Normalize to 100%
total = sum(real_probs)
baseline_ideology = {ideol: p / total * 100 for ideol, p in zip(real_ideologies, real_probs)}

# Map
ideology_map = {
    # Democratic
    "democrat": "Democratic",
    "democratic": "Democratic",

    # Republican
    "republican": "Republican",
    "conservative": "Republican",
    "family-oriented conservative": "Republican",
    "fiscally conservative": "Republican",

    # Libertarian
    "libertarian": "Libertarian",

    # Green
    "green": "Green",
    "eco": "Green",
    "environmental": "Green",
    "climate": "Green",
    "pro-environmental": "Green",

    # Progressive
    "progressive": "Progressive",
    "social justice": "Progressive",
    "racial justice": "Progressive",
    "equity": "Progressive",
    "sustainability": "Progressive",
    "community-driven": "Progressive",
    

    # Liberal
    "liberal": "Liberal",
    "center-left": "Liberal",

    # Moderate
    "moderate": "Moderate",
    "centrism": "Moderate",
    "leaning towards progressive policy": "Moderate",
    "socially conservative": "Moderate",

    # Other / Ambiguos
    "not applicable": "Other",
    "not yet defined": "Other",
    "influenced": "Other",
    "cultural preservation": "Other",
    "fairness": "Other",
    "diaspora": "Other",
    "undefined": "Other",
    "advocate": "Other"
}



def normalize_ideology(text):
    if not isinstance(text, str):
        return "__None__"
    text_l = text.lower()
    for key, val in ideology_map.items():
        if key in text_l:
            return val
    return "__None__"


# --- Model Analysis ---
model_ideology = {}
ideology_mae = {}

for model, filepath in model_files.items():
    with open(filepath) as f:
        data = json.load(f)

    counter = Counter()
    for person in data:
        try:
            raw = person["Identity"]["Political Ideology"]
            norm = normalize_ideology(raw)
            counter[norm] += 1
        except:
            continue

    total = sum(counter.values())
    dist = {k: v / total * 100 for k, v in counter.items()}
    model_ideology[model] = dist

    # MAE
    mae = 0
    for cat in baseline_ideology:
        real = baseline_ideology.get(cat, 0)
        pred = dist.get(cat, 0)
        mae += abs(real - pred)
    ideology_mae[model] = round(mae / len(baseline_ideology), 2)

# --- Printing ---
def print_top_ideologies(name, dist, top_n=30):
    print(f"\n{name}")
    print("-" * 40)


    filtered = {
        k: v for k, v in dist.items()
        if k is not None and isinstance(v, (int, float))
    }

    for cat, pct in sorted(filtered.items(), key=lambda x: x[1], reverse=True)[:top_n]:
        print(f"{cat:<20} {pct:.2f}%")


    none_pct = dist.get("__None__")
    if none_pct is not None:
        print(f"{'Unmapped / None':<20} {none_pct:.2f}%")


print_top_ideologies("Cambridge", baseline_ideology)
for model in model_files:
    print_top_ideologies(model, model_ideology[model])
    print(f"MAE: {ideology_mae[model]}%")



# === Section: Marital Status===
# Map
marital_map = {
    "not separated": "Married, not separated",
    "widowed": "Widowed",
    "divorced": "Divorced",
    "separated": "Separated",
    "never married": "Never Married",
    "single": "Never Married",
    "unmarried": "Never Married"
}

def normalize_marital(text):
    if not isinstance(text, str):
        return "__None__"
    text_l = text.lower()
    for key, val in marital_map.items():
        if key in text_l:
            return val
    return "__None__"

# Real distribution
baseline_marital = {
    "Married, not separated": (34.0 + 31.3) / 2,
    "Widowed": (1.1 + 4.0) / 2,
    "Divorced": (4.2 + 7.5) / 2,
    "Separated": (0.5 + 1.1) / 2,
    "Never Married": (60.1 + 56.2) / 2
}

# Model processing
model_marital = {}

for model, filepath in model_files.items():
    with open(filepath) as f:
        data = json.load(f)

    counter = Counter()
    for p in data:
        try:
            raw = p["Behavioral"]["Social"]["Relationships"]["Marital Status"]
            norm = normalize_marital(raw)
            if norm == "__None__":
                counter["__None__"] += 1
            else:
                counter[norm] += 1
        except:
            counter["__None__"] += 1

    total = sum(counter.values())
    dist = {k: v / total * 100 for k, v in counter.items()}
    model_marital[model] = dist

# MAE
def compute_mae(baseline, model_dist, categories):
    return round(
        sum(abs(baseline.get(cat, 0) - model_dist.get(cat, 0)) for cat in categories) / len(categories),
        2
    )

marital_categories = list(baseline_marital.keys())
marital_mae = {
    model: compute_mae(baseline_marital, dist, marital_categories)
    for model, dist in model_marital.items()
}

# Printing
def print_top_marital(name, raw_counter, mapping_func=None, top_n=10):
    print(f"\n{name}")
    print("-" * 40)

    if not isinstance(raw_counter, Counter):
        raw_counter = Counter(raw_counter)

    total = sum(raw_counter.values())
    most_common = raw_counter.most_common(top_n)

    for raw_val, count in most_common:
        mapped_val = mapping_func(raw_val) if mapping_func else raw_val
        label = mapped_val if mapped_val != "__None__" else raw_val
        pct = 100 * count / total
        print(f"{label:<30} {pct:.2f}%")


print_top_marital("Cambridge", baseline_marital)
for model in model_files:
    print_top_marital(model, model_marital[model])
    print(f"MAE: {marital_mae[model]}%")




####################################################Marital Status####################################################
# === Section: Disabilities==

# REal data per age
probabilities = {
    "hearing": [0.7, 1.1, 0.7, 0.4, 1.3, 10.3],
    "vision": [0, 0, 0.9, 0.5, 1.6, 2.3],
    "cognitive": [3.3, 0, 5.2, 4.5, 6.4, 6.8],
    "ambulatory": [0, 0, 2.3, 1.4, 3.8, 12.0],
    "self_care": [0, 0, 0.5, 0.2, 0.8, 5.1],
    "independent_living": [0, 0, 1.8, 1.2, 2.8, 11.3]
}
age_ranges = [(0, 5), (5, 18), (18, 34), (35, 64), (65, 74), (75, 100)]
age_weights = [high - low for (low, high) in age_ranges]
total_weight = sum(age_weights)


baseline_disabilities = {}
total_dis = [0] * len(age_ranges)
for disability, probs in probabilities.items():
    for i, p in enumerate(probs):
        total_dis[i] += p

for disability, probs in probabilities.items():
    weighted_sum = sum(p * w for p, w in zip(probs, age_weights))
    baseline_disabilities[disability] = round(weighted_sum / total_weight, 2)

weighted_no_dis = sum((100 - total_dis[i]) * age_weights[i] for i in range(len(age_weights)))
baseline_disabilities["No disability"] = round(weighted_no_dis / total_weight, 2)

# Mapping
disability_mapping = {
    "hearing": "hearing",
    "hearing impairment": "hearing",
    "vision": "vision",
    "visual": "vision",
    "cognitive": "cognitive",
    "cognitive:": "cognitive",
    "ambulatory": "ambulatory",
    "self-care": "self_care",
    "self care": "self_care",
    "independent living": "independent_living",
    "independent": "independent_living",
    "no disability": "No disability",
    "no disability,": "No disability",
    "none": "No disability",
    "none,": "No disability",
    "none reported": "No disability",
    "no known disabilities": "No disability",
    "no diagnosed disabilities": "No disability",
    "no disabilities": "No disability"
}

def normalize_disability(item):
    if not isinstance(item, str):
        return None
    text = item.lower()
    for key, val in disability_mapping.items():
        if key in text:
            return val
    return None


model_disability = {}
model_disability_raw = {}
model_mae = {}

for model, file in model_files.items():
    with open(file) as f:
        data = json.load(f)

    raw_counter = Counter()
    mapped_counter = Counter()

    for person in data:
        try:
            disabilities = person["Physical/Biological/Movility"]["Health"].get("Disabilities")
            if isinstance(disabilities, str):
                disabilities = [disabilities]
            if not isinstance(disabilities, list):
                continue
            for d in disabilities:
                raw_counter[d] += 1
                norm = normalize_disability(d)
                if norm:
                    mapped_counter[norm] += 1
        except:
            continue

    total = sum(mapped_counter.values())
    dist = {k: v / total * 100 for k, v in mapped_counter.items()}
    model_disability[model] = dist
    model_disability_raw[model] = raw_counter

def compute_mae(baseline, dist):
    mae = 0
    for key in baseline:
        real = baseline[key]
        pred = dist.get(key, 0)
        mae += abs(real - pred)
    return round(mae / len(baseline), 2)

for model in model_files:
    model_mae[model] = compute_mae(baseline_disabilities, model_disability[model])

#Printing results
print("Cambridge")
print("-" * 40)
for k, v in baseline_disabilities.items():
    print(f"{k:<25} {v:.2f}%")

for model in model_files:
    print(f"\n{model} – Top disability expressions")
    print("-" * 50)
    raw = model_disability_raw[model]
    total = sum(raw.values())
    for d, count in raw.most_common(20):
        pct = count / total * 100
        print(f"{d:<40} {count} times   {pct:.2f}%")
    print(f"MAE: {model_mae[model]}%")