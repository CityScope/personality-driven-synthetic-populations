"""
emotion_sentiment_analysis.py

This script analyzes emotional and sentiment signals from personality profile texts
generated by various language models (e.g., LLaMA, Dolphin, Mistral, Qwen).

For both "General" and "Personality" descriptions, it computes:
- Mean emotion scores using GoEmotions (SamLowe/roberta-base-go_emotions)
- Sentiment distribution and mean sentiment scores using RoBERTa Twitter model

It then visualizes comparisons across models using bar chart subplots.

Author: José Miguel Nicolás García
"""

import json
import numpy as np
import matplotlib.pyplot as plt
from transformers import pipeline
from collections import Counter, defaultdict
import os

# === Model settings ===

model_files = {
    "LLaMA": "profiles_cambridge-llama3.1_8b.json",
    "Dolphin": "profiles_cambridge-dolphin-llama3_8b.json",
    "Mistral": "profiles_cambridge-mistral_7b.json",
    "Qwen": "profiles_cambridge-qwen3_8b.json"
}

model_colors = {
    "LLaMA": "#4E79A7",
    "Dolphin": "#59A14F",
    "Mistral": "#F28E2B",
    "Qwen": "#E15759"
}

# Increase font sizes globally for legibility
plt.rcParams.update({
    'font.size': 14,             
    'axes.titlesize': 16,        
    'axes.labelsize': 16,        
    'xtick.labelsize': 16,       
    'ytick.labelsize': 14,      
    'legend.fontsize': 13,       
    'figure.titlesize': 18       
})

# === Result storage ===
# Nested dictionaries: {category -> model -> score_dict}
goemotions_scores = {
    "General": defaultdict(dict),
    "Personality": defaultdict(dict)
}
roberta_scores = {
    "General": defaultdict(dict),
    "Personality": defaultdict(dict)
}
roberta_counts = {
    "General": defaultdict(dict),
    "Personality": defaultdict(dict)
}


def load_descriptions(json_path):
    """
    Loads general and personality description strings from a JSON profile file.

    Args:
        json_path (str): Path to the JSON file.

    Returns:
        tuple: (general_descriptions, personality_descriptions)
    """
    with open(json_path, "r") as file:
        profiles = json.load(file)

    general_desc = [p.get("General", {}).get("General Description", "") for p in profiles]
    personality_desc = [p.get("Psychological and Cognitive", {})
                          .get("Personality/Big Five Traits", {})
                          .get("General Big Five Description", "")
                        for p in profiles]

    return list(filter(None, general_desc)), list(filter(None, personality_desc))


def analyze_goemotions(descriptions, model_name, category):
    """
    Applies GoEmotions classifier to a list of texts and computes mean scores per emotion.

    Args:
        descriptions (list): List of input texts.
        model_name (str): Name of the LLM used to generate profiles.
        category (str): Either "General" or "Personality".
    """
    classifier = pipeline(task="text-classification", model="SamLowe/roberta-base-go_emotions", top_k=None)
    results = classifier(descriptions)

    sentiment_scores = {}
    for entry in results:
        for sentiment in entry:
            label = sentiment['label']
            sentiment_scores.setdefault(label, []).append(sentiment['score'])

    mean_scores = {k: np.mean(v) for k, v in sentiment_scores.items()}
    goemotions_scores[category][model_name] = mean_scores


def analyze_roberta(descriptions, model_name, category):
    """
    Applies RoBERTa sentiment classifier and stores both mean scores and distribution.

    Args:
        descriptions (list): List of input texts.
        model_name (str): Name of the LLM used to generate profiles.
        category (str): Either "General" or "Personality".
    """
    sentiment_pipeline = pipeline("sentiment-analysis", model="cardiffnlp/twitter-roberta-base-sentiment-latest")
    results = sentiment_pipeline(descriptions)

    sentiment_counts = Counter([r["label"] for r in results])
    sentiment_scores = defaultdict(list)
    for r in results:
        sentiment_scores[r["label"]].append(r["score"])

    mean_scores = {k: np.mean(v) for k, v in sentiment_scores.items()}
    roberta_scores[category][model_name] = mean_scores

    total = sum(sentiment_counts.values())
    normalized = {label: (count / total * 100) for label, count in sentiment_counts.items()}
    roberta_counts[category][model_name] = normalized


def plot_comparison_subplots(data_dict_all_categories, title, ylabel, filename, is_percentage=False):
    """
    Generates 2-row bar chart comparing emotion/sentiment metrics for each model.

    Args:
        data_dict_all_categories (dict): Nested dict: {category -> model -> score_dict}
        title (str): Figure title.
        ylabel (str): Y-axis label.
        filename (str): Output image filename.
        is_percentage (bool): Whether to append "%" to bar values.
    """
    categories = ["General", "Personality"]
    labels_all = sorted(set(k for cat in categories for model in data_dict_all_categories[cat] for k in data_dict_all_categories[cat][model]))
    x = np.arange(len(labels_all))
    width = 0.2

    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(14, 10), sharex=True)

    for row_idx, category in enumerate(categories):
        ax = axes[row_idx]
        data_dict = data_dict_all_categories[category]

        for i, (model_name, values) in enumerate(data_dict.items()):
            heights = [values.get(label, 0) for label in labels_all]
            offset = (i - len(data_dict)/2) * width + width/2
            bars = ax.bar(x + offset, heights, width=width, label=model_name, color=model_colors[model_name])

            # Optional: label bars with exact values
            # for rect, h in zip(bars, heights):
            #     if h > 0:
            #         ax.text(rect.get_x() + rect.get_width()/2, h + 0.5, f"{h:.1f}%" if is_percentage else f"{h:.2f}",
            #                 ha='center', va='bottom', fontsize=10)

        ax.set_ylabel(ylabel)
        ax.set_title(f"{category} Descriptions")

    axes[-1].set_xticks(x)
    axes[-1].set_xticklabels(labels_all, rotation=45, ha="right")
    axes[0].legend(loc='upper right')
    fig.suptitle(title, fontsize=16)
    fig.tight_layout(rect=[0, 0, 1, 0.96])
    fig.savefig(f"{filename}.png")
    plt.close()


def process_all_models():
    """
    Main processing loop:
    - Loads all model profile files.
    - Extracts descriptions.
    - Applies emotion/sentiment analysis.
    - Plots comparison figures.
    """
    for model_name, json_path in model_files.items():
        if not os.path.exists(json_path):
            print(f"File not found: {json_path}")
            continue

        print(f"\nProcessing: {model_name}")
        general_desc, personality_desc = load_descriptions(json_path)

        if general_desc:
            analyze_goemotions(general_desc, model_name, "General")
            analyze_roberta(general_desc, model_name, "General")

        if personality_desc:
            analyze_goemotions(personality_desc, model_name, "Personality")
            analyze_roberta(personality_desc, model_name, "Personality")

    plot_comparison_subplots(goemotions_scores, "Emotions Mean Scores", "Mean Score", "ALL_GoEmotions_Comparison")
    plot_comparison_subplots(roberta_scores, "Mean Sentiment Scores", "Mean Score", "ALL_Roberta_Mean_Comparison")
    plot_comparison_subplots(roberta_counts, "Sentiment Distribution", "Percentage (%)", "ALL_Roberta_Counts_Percent_Comparison", is_percentage=True)


if __name__ == "__main__":
    process_all_models()
