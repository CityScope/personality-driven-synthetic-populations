"""
semantic_traits_analysis.py

This script analyzes semantic traits (e.g., Job, Life Goals, Strengths, Weaknesses, etc.)
from multiple personality profile datasets generated by various language models.

For each trait and model:
- It computes the number of distinct textual responses.
- It identifies the top n most frequent values (excluding stopwords).
- It measures semantic diversity via pairwise cosine similarity of sentence embeddings.

The output is printed in two parts:
1. A summary DataFrame with statistics per trait and model.
2. Top-n most frequent values per trait-model pair.

Author: José Miguel Nicolás García
"""

import json
import os
import numpy as np
import pandas as pd
from sentence_transformers import SentenceTransformer, util
from collections import Counter

# Model files
model_files = {
    "LLaMA": "profiles_cambridge-llama3.1_8b.json",
    "Dolphin": "profiles_cambridge-dolphin-llama3_8b.json",
    "Mistral": "profiles_cambridge-mistral_7b.json",
    "Qwen": "profiles_cambridge-qwen3_8b.json"
}

# Stop words
stop_words = {
    'a', 'an', 'the', 'and', 'is', 'of', 'to', 'with', 'in', 'on', 'for', 'from',
    'at', 'by', 'as', 'this', 'that', 'it', 'he', 'she', 'they', 'we', 'who',
    'but', 'or', 'his', 'her', 'its', 'our', 'their', 'be', 'been', 'being'
}

# Traits to analyze and their paths
traits_to_analyze = {
    "Job": ["Profession", "Job"],
    "Life Goals": ["Psychological and Cognitive", "Motivations", "Life Goals"],
    "Strengths": ["Psychological and Cognitive", "Strengths"],
    "Weaknesses": ["Psychological and Cognitive", "Weaknesses"],
    "Daily Routine": ["Behavioral", "Habits and Routines", "Daily Routine"],
    "Social Skills": ["Behavioral", "Social", "Friends", "Social Skills"],
}

# Load model for semantic analysis 
embedding_model = SentenceTransformer("all-MiniLM-L6-v2", device="cpu")

def extract_trait_value(person, path):
    """
    Navigates a nested JSON profile to extract a specific trait value.

    Args:
        person (dict): The JSON object of a profile.
        path (List[str]): List of nested keys.

    Returns:
        str or list or None: The extracted value, if found.
    """
    try:
        value = person
        for key in path:
            value = value[key]
        return value
    except (KeyError, TypeError):
        return None

def analyze_trait(values):
    """
    Analyzes the distribution and semantic diversity of a given list of trait values.

    Args:
        values (List[str]): List of strings describing the trait.

    Returns:
        tuple:
            - int: Number of distinct (cleaned) values.
            - List[str]: Top-N most frequent values (excluding stopwords).
            - float: Semantic diversity score (1 - average cosine similarity).
    """
    cleaned_values = [v.strip().lower() for v in values if isinstance(v, str) and v.strip()]
    distinct_count = len(set(cleaned_values))
    value_counts = Counter(cleaned_values)
    top_n = 55  # Top 5 by default
    top_5 = [v for v, c in value_counts.most_common() if v not in stop_words][:top_n]


    # Semantic diversity
    if len(cleaned_values) > 1:
        embeddings = embedding_model.encode(cleaned_values, convert_to_tensor=True)
        cosine_sim_matrix = util.pytorch_cos_sim(embeddings, embeddings)
        upper_triangle = cosine_sim_matrix[np.triu_indices(len(cleaned_values), k=1)]
        semantic_diversity = 1 - upper_triangle.mean().item()
    else:
        semantic_diversity = 0.0

    return distinct_count, top_5, semantic_diversity

# === Main Analysis ===
results = []
top5_values_dict = {}

for trait_name, trait_path in traits_to_analyze.items():
    for model_name, file_path in model_files.items():
        key = f"{trait_name} - {model_name}"
        if not os.path.exists(file_path):
            results.append({
                "Trait": trait_name,
                "Model": model_name,
                "Distinct Values": "File not found",
                "Semantic Diversity": ""
            })
            top5_values_dict[key] = []
            continue

        with open(file_path, 'r') as f:
            data = json.load(f)

        values = []
        for person in data:
            val = extract_trait_value(person, trait_path)
            if isinstance(val, list):
                values.extend([v for v in val if isinstance(v, str)])
            elif isinstance(val, str):
                values.append(val)

        distinct, top5, diversity = analyze_trait(values)

        results.append({
            "Trait": trait_name,
            "Model": model_name,
            "Distinct Values": distinct,
            "Semantic Diversity": round(diversity, 4)
        })

        top5_values_dict[key] = top5


# === Output Results ===
# Print dataframe
df = pd.DataFrame(results)
print(df.to_string(index=False))

# Print top-5 separately
print("\nTop-5 Most Frequent Values (per Trait and Model):\n")
for key, top5 in top5_values_dict.items():
    print(f"{key}:")
    for i, val in enumerate(top5, 1):
        print(f"  {i}. {val}")
    print()
